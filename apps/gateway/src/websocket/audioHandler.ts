import { Socket } from 'socket.io';
import { audioProcessor, AudioChunk } from '../services/audioProcessor';
import { asrService } from '../services/asrService';
import { SessionNotifier } from './index';

const isDevelopment = process.env.NODE_ENV === 'development';

export interface PresentialAudioData {
  sessionId: string;
  audioData: number[]; // Array serializado do Float32Array
  timestamp: number;
  sampleRate: number;
}

export interface PresentialSessionData {
  sessionId: string;
  consultationId: string;
  timestamp: string;
}

export function setupPresentialAudioHandlers(socket: Socket, notifier: SessionNotifier): void {
  
  // Handler para √°udio do m√©dico
  socket.on('presential:audio:doctor', (data: PresentialAudioData) => {
    try {
      const { sessionId, audioData, timestamp, sampleRate } = data;
      
      if (!sessionId || !audioData || !Array.isArray(audioData)) {
        socket.emit('error', {
          code: 'INVALID_AUDIO_DATA',
          message: 'Dados de √°udio inv√°lidos para m√©dico'
        });
        return;
      }

      // Converter array de volta para Float32Array
      const float32AudioData = new Float32Array(audioData);

      // üîç DEBUG: Verificar se os dados chegam zerados
      const hasNonZeroData = float32AudioData.some(value => value !== 0);
      const maxValue = Math.max(...float32AudioData);
      const minValue = Math.min(...float32AudioData);
      const avgValue = float32AudioData.reduce((sum, val) => sum + Math.abs(val), 0) / float32AudioData.length;
      
      /**
      console.log(`üîç DEBUG [AUDIO_RECEPTION] doctor:`, {
        arrayLength: audioData.length,
        float32Length: float32AudioData.length,
        hasNonZeroData,
        maxValue: maxValue.toFixed(6),
        minValue: minValue.toFixed(6),
        avgValue: avgValue.toFixed(6),
        first10Values: Array.from(float32AudioData.slice(0, 10)).map(v => v.toFixed(6))
      });
       */

      if (!hasNonZeroData) {
        console.warn(`‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è DADOS ZERADOS RECEBIDOS do frontend para doctor!`);
        return; // N√£o processar dados zerados
      }

      // Criar chunk de √°udio
      const audioChunk: AudioChunk = {
        sessionId,
        channel: 'doctor',
        audioData: float32AudioData,
        timestamp,
        sampleRate
      };

      // Processar √°udio
      audioProcessor.processAudioChunk(audioChunk);

      if (isDevelopment) {
        //console.log(`üé§ √Åudio m√©dico recebido: ${audioData.length} samples - Sess√£o: ${sessionId}`);
      }
      
    } catch (error) {
      console.error('Erro ao processar √°udio do m√©dico:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'AUDIO_PROCESSING_ERROR',
          message: 'Erro ao processar √°udio do m√©dico'
        }
      });
    }
  });

  // Handler para √°udio do paciente
  socket.on('presential:audio:patient', (data: PresentialAudioData) => {
    try {
      const { sessionId, audioData, timestamp, sampleRate } = data;
      
      if (!sessionId || !audioData || !Array.isArray(audioData)) {
        socket.emit('error', {
          code: 'INVALID_AUDIO_DATA',
          message: 'Dados de √°udio inv√°lidos para paciente'
        });
        return;
      }

      // Converter array de volta para Float32Array
      const float32AudioData = new Float32Array(audioData);

      // üîç DEBUG: Verificar se os dados chegam zerados
      const hasNonZeroData = float32AudioData.some(value => value !== 0);
      const maxValue = Math.max(...float32AudioData);
      const minValue = Math.min(...float32AudioData);
      const avgValue = float32AudioData.reduce((sum, val) => sum + Math.abs(val), 0) / float32AudioData.length;
      
      console.log(`üîç DEBUG [AUDIO_RECEPTION] patient:`, {
        arrayLength: audioData.length,
        float32Length: float32AudioData.length,
        hasNonZeroData,
        maxValue: maxValue.toFixed(6),
        minValue: minValue.toFixed(6),
        avgValue: avgValue.toFixed(6),
        first10Values: Array.from(float32AudioData.slice(0, 10)).map(v => v.toFixed(6))
      });

      if (!hasNonZeroData) {
        console.warn(`‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è DADOS ZERADOS RECEBIDOS do frontend para patient!`);
        return; // N√£o processar dados zerados
      }

      // Criar chunk de √°udio
      const audioChunk: AudioChunk = {
        sessionId,
        channel: 'patient',
        audioData: float32AudioData,
        timestamp,
        sampleRate
      };

      // Processar √°udio
      audioProcessor.processAudioChunk(audioChunk);

      if (isDevelopment) {
        //console.log(`üé§ √Åudio paciente recebido: ${audioData.length} samples - Sess√£o: ${sessionId}`);
      }
      
    } catch (error) {
      console.error('Erro ao processar √°udio do paciente:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'AUDIO_PROCESSING_ERROR',
          message: 'Erro ao processar √°udio do paciente'
        }
      });
    }
  });

  // Handler para iniciar grava√ß√£o presencial
  socket.on('presential:start_recording', (data: PresentialSessionData) => {
    try {
      const { sessionId, consultationId } = data;
      
      if (!sessionId) {
        socket.emit('error', {
          code: 'INVALID_SESSION_ID',
          message: 'ID da sess√£o √© obrigat√≥rio'
        });
        return;
      }

      // Configurar listeners do processador de √°udio para esta sess√£o
      setupAudioProcessorListeners(sessionId, notifier);

      // Notificar outros participantes que a grava√ß√£o iniciou
      notifier.emitProcessingStatus(sessionId, 'processing', 'Grava√ß√£o iniciada');
      
      // Confirmar in√≠cio da grava√ß√£o
      socket.emit('presential:recording_started', {
        sessionId,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao iniciar grava√ß√£o presencial:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'START_RECORDING_ERROR',
          message: 'Erro ao iniciar grava√ß√£o presencial'
        }
      });
    }
  });

  // Handler para parar grava√ß√£o presencial
  socket.on('presential:stop_recording', (data: { sessionId: string; timestamp: string }) => {
    try {
      const { sessionId } = data;
      
      if (!sessionId) {
        socket.emit('error', {
          code: 'INVALID_SESSION_ID',
          message: 'ID da sess√£o √© obrigat√≥rio'
        });
        return;
      }

      // PRIORIT√ÅRIO: Processar frases pendentes primeiro
      audioProcessor.flushPendingPhrases(sessionId);
      
      // CR√çTICO: Remover listeners para evitar vazamentos
      const listenersToRemove = activeListeners.get(sessionId);
      if (listenersToRemove) {
        globalListenerCount--;
        audioProcessor.off('audio:processed', listenersToRemove.onAudioProcessed);
        audioProcessor.off('audio:voice_activity', listenersToRemove.onVoiceActivity);
        audioProcessor.off('audio:silence', listenersToRemove.onSilence);
        activeListeners.delete(sessionId);
      }
      
      // DESABILITADO: N√£o processar buffers restantes no modo frases completas
      // audioProcessor.flushPendingBuffers(sessionId);

      // Limpar buffers da sess√£o
      audioProcessor.clearSession(sessionId);

      // Notificar fim da grava√ß√£o
      notifier.emitProcessingStatus(sessionId, 'completed', 'Grava√ß√£o finalizada');
      
      // Confirmar fim da grava√ß√£o
      socket.emit('presential:recording_stopped', {
        sessionId,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao parar grava√ß√£o presencial:', error);
      socket.emit('session:error', {
        sessionId: data.sessionId,
        error: {
          code: 'STOP_RECORDING_ERROR',
          message: 'Erro ao finalizar grava√ß√£o presencial'
        }
      });
    }
  });

  // Handler para obter estat√≠sticas de √°udio
  socket.on('presential:audio_stats', (data: { sessionId: string }) => {
    try {
      const stats = audioProcessor.getStats();
      
      socket.emit('presential:audio_stats_response', {
        sessionId: data.sessionId,
        stats,
        timestamp: new Date().toISOString()
      });

    } catch (error) {
      console.error('Erro ao obter estat√≠sticas de √°udio:', error);
      socket.emit('error', {
        code: 'AUDIO_STATS_ERROR',
        message: 'Erro ao obter estat√≠sticas de √°udio'
      });
    }
  });
}

// Map para controlar listeners ativos por sess√£o
const activeListeners = new Map<string, {
  onAudioProcessed: (processedChunk: any) => void;
  onVoiceActivity: (data: any) => void;
  onSilence: (data: any) => void;
}>();

// üîç DEBUG: Contador global de listeners
let globalListenerCount = 0;

// üõ°Ô∏è PROTE√á√ÉO CONTRA RACE CONDITIONS: Set de IDs enviados recentemente
const sentTranscriptionIds = new Set<string>();


// Configurar listeners do processador de √°udio para uma sess√£o
function setupAudioProcessorListeners(sessionId: string, notifier: SessionNotifier): void {
  
  // CR√çTICO: Remover listeners anteriores se existirem
  const existingListeners = activeListeners.get(sessionId);
  if (existingListeners) {
    globalListenerCount--;
    audioProcessor.off('audio:processed', existingListeners.onAudioProcessed);
    audioProcessor.off('audio:voice_activity', existingListeners.onVoiceActivity);
    audioProcessor.off('audio:silence', existingListeners.onSilence);
  }
  
  // Listener para √°udio processado
  const onAudioProcessed = (processedChunk: any) => {
    if (processedChunk.sessionId === sessionId) {
      // üîç DEBUG [AUDIO_PROCESSING]: Come√ßou processar √°udio
      console.log(`üîç DEBUG [AUDIO_PROCESSING] ${processedChunk.channel} - ${Math.round(processedChunk.duration)}ms`);
      
      // üîç DEBUG [TRANSCRIPTION_SEND]: Enviado para transcri√ß√£o
      console.log(`üîç DEBUG [TRANSCRIPTION_SEND] ${processedChunk.channel} ‚Üí Whisper`);
      
      // Enviar para ASR
      asrService.processAudio(processedChunk)
        .then((transcription) => {
          if (transcription) {
            // üîç DEBUG [TRANSCRIPTION_RECEIVED]: Transcri√ß√£o recebida
            console.log(`üîç DEBUG [TRANSCRIPTION_RECEIVED] ${transcription.speaker}: "${transcription.text}"`);

            // Formatar transcri√ß√£o para o frontend
            const utterance = {
              id: transcription.id,
              speaker: transcription.speaker,
              text: transcription.text,
              timestamp: transcription.timestamp,
              confidence: transcription.confidence
            };
            
            // üõ°Ô∏è PROTE√á√ÉO CONTRA RACE CONDITION: Verificar se ID j√° foi enviado
            if (sentTranscriptionIds.has(transcription.id)) {
              return;
            }
            
            // Marcar como enviado ANTES de enviar (evita race condition)
            sentTranscriptionIds.add(transcription.id);
            
            // üîç DEBUG [WEBSOCKET_SEND]: Enviado para WebSocket
            console.log(`üîç DEBUG [WEBSOCKET_SEND] ${transcription.speaker} ‚Üí Frontend`);
            
            // Emitir transcri√ß√£o via WebSocket
            notifier.emitTranscriptionUpdate(sessionId, utterance);
            
            // Trigger gera√ß√£o de sugest√µes ap√≥s transcri√ß√£o
            triggerSuggestionGeneration(sessionId, utterance, notifier);
            
            // Limpeza peri√≥dica do Set (manter √∫ltimos 1000 IDs)
            if (sentTranscriptionIds.size > 1000) {
              const idsArray = Array.from(sentTranscriptionIds);
              sentTranscriptionIds.clear();
              // Manter s√≥ os √∫ltimos 500 IDs
              idsArray.slice(-500).forEach(id => sentTranscriptionIds.add(id));
            }
          }
        })
        .catch((error) => {
          console.error(`üîç DEBUG [TRANSCRIPTION_ERROR]:`, error);
          notifier.emitSessionError(sessionId, {
            code: 'TRANSCRIPTION_ERROR',
            message: 'Erro no processamento de transcri√ß√£o'
          });
        });
    }
  };

  // Listener para atividade de voz
  const onVoiceActivity = (data: any) => {
    if (data.sessionId === sessionId) {
      // üîç DEBUG [VOICE_START/END]: Log in√≠cio/fim da fala
      if (data.isActive) {
        console.log(`üîç DEBUG [VOICE_START] ${data.channel} come√ßou a falar`);
      } else {
        console.log(`üîç DEBUG [VOICE_END] ${data.channel} terminou de falar`);
      }
      
      // Emitir evento de atividade de voz
      notifier.emitVoiceActivity(sessionId, data.channel, data.isActive);
    }
  };

  // Listener para sil√™ncio
  const onSilence = (data: any) => {
    // Removido - log desnecess√°rio para o tunnel
  };

  // Registrar listeners
  globalListenerCount++;
  audioProcessor.on('audio:processed', onAudioProcessed);
  audioProcessor.on('audio:voice_activity', onVoiceActivity);
  audioProcessor.on('audio:silence', onSilence);

  // CR√çTICO: Armazenar refer√™ncias dos listeners para remo√ß√£o futura
  activeListeners.set(sessionId, {
    onAudioProcessed,
    onVoiceActivity,
    onSilence
  });
}

// Fun√ß√£o para triggerar gera√ß√£o de sugest√µes
async function triggerSuggestionGeneration(sessionId: string, utterance: any, notifier: any): Promise<void> {
  try {
    console.log(`ü§ñ Triggering suggestion generation for session ${sessionId} after utterance: "${utterance.text.substring(0, 50)}..."`);
    
    // Importar servi√ßos necess√°rios
    const { suggestionService } = await import('../services/suggestionService');
    const { db } = await import('../config/database');
    
    // Buscar informa√ß√µes da sess√£o
    const session = await db.getSession(sessionId);
    if (!session) {
      console.log('‚ö†Ô∏è Sess√£o n√£o encontrada para gera√ß√£o de sugest√µes');
      return;
    }

    // Buscar utterances recentes da sess√£o
    const utterances = await db.getSessionUtterances(sessionId);
    
    // Criar contexto para gera√ß√£o de sugest√µes
    const context = {
      sessionId,
      patientName: 'Paciente', // TODO: Buscar nome real do paciente
      sessionDuration: Math.floor((Date.now() - new Date(session.created_at).getTime()) / (1000 * 60)),
      consultationType: session.session_type || 'presencial',
      utterances: utterances.slice(-10), // √öltimas 10 utterances
      specialty: 'clinica_geral' // TODO: Determinar especialidade baseada no contexto
    };

    console.log(`üìä Context for suggestions: ${context.utterances.length} utterances, ${context.sessionDuration}min duration`);

    // Gerar sugest√µes
    const suggestions = await suggestionService.generateSuggestions(context);
    
    if (suggestions && suggestions.suggestions.length > 0) {
      console.log(`ü§ñ ${suggestions.suggestions.length} sugest√µes geradas para sess√£o ${sessionId}`);
      
      // Emitir sugest√µes para a sess√£o usando o notifier passado
      notifier.emitAISuggestions(sessionId, suggestions.suggestions);
      notifier.emitContextUpdate(sessionId, suggestions.context_analysis);
      
      console.log(`üì° Sugest√µes enviadas via WebSocket para sess√£o ${sessionId}`);
    } else {
      console.log(`ü§ñ Nenhuma sugest√£o gerada para sess√£o ${sessionId}`);
    }

  } catch (error) {
    console.error('‚ùå Erro ao triggerar gera√ß√£o de sugest√µes:', error);
  }
}
