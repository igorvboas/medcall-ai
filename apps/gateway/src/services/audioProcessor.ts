import { EventEmitter } from 'events';

export interface AudioChunk {
  sessionId: string;
  channel: 'doctor' | 'patient';
  audioData: Float32Array;
  timestamp: number;
  sampleRate: number;
}

export interface ProcessedAudioChunk {
  sessionId: string;
  channel: 'doctor' | 'patient';
  audioBuffer: Buffer;
  timestamp: number;
  sampleRate: number;
  duration: number;
  hasVoiceActivity: boolean;
  averageVolume: number;
}

export interface AudioProcessorEvents {
  'audio:processed': (chunk: ProcessedAudioChunk) => void;
  'audio:silence': (data: { sessionId: string; channel: 'doctor' | 'patient' }) => void;
  'audio:voice_activity': (data: { sessionId: string; channel: 'doctor' | 'patient'; isActive: boolean }) => void;
  'error': (error: Error) => void;
}

export class AudioProcessor extends EventEmitter {
  private buffers: Map<string, Float32Array[]> = new Map();
  // üéØ OTIMIZADO PARA TRANSCRI√á√ÉO DE QUALIDADE
  private vadThreshold = 0.05; // Mais sens√≠vel para captar voz baixa (era 0.08)
  private bufferDuration = 1000; // Dura√ß√£o do buffer em ms
  private maxBufferSize = 44100; // M√°ximo de samples no buffer (1 segundo a 44.1kHz)
  private minVoiceDurationMs = 800; // Reduzido para captar frases curtas importantes (era 2000)
  private silenceThresholdMs = 3000; // Reduzido para ser mais responsivo (era 5000)
  private lastVoiceActivity: Map<string, number> = new Map(); // Timestamp da √∫ltima atividade de voz
  private consecutiveVoiceChunks: Map<string, number> = new Map(); // Contador de chunks consecutivos com voz
  private minConsecutiveChunks = 1; // Mais responsivo (era 2)
  
  // Par√¢metros para frases completas - OTIMIZADO
  private phraseBuffers: Map<string, Float32Array[]> = new Map(); // Buffer para agrupar frases completas
  private phraseTimestamps: Map<string, number> = new Map(); // Timestamp do in√≠cio da frase
  private phraseEndSilenceMs = 1200; // Sil√™ncio que indica fim de frase - mais responsivo (era 2000)
  private maxPhraseLength = 15000; // M√°ximo 15s por frase para evitar perda de contexto
  
  // Controle para evitar processamento parcial
  private disablePartialProcessing = true; // NOVA FLAG - s√≥ processa frases completas
  
  // üõ°Ô∏è CONTROLE DE DEDUPLICA√á√ÉO TOTAL - SOLU√á√ÉO PARA DUPLICA√á√ïES
  private processingInProgress: Map<string, boolean> = new Map(); // Flag de processamento em andamento
  private lastProcessedTimestamp: Map<string, number> = new Map(); // Timestamp do √∫ltimo processamento
  private processedChunkIds: Set<string> = new Set(); // IDs de chunks j√° processados
  private globalProcessingLock: Map<string, boolean> = new Map(); // Lock global por canal
  
  // üîç SISTEMA DE DEBUGGING DETALHADO
  private debugTracker: Map<string, any[]> = new Map(); // Rastrear eventos por sess√£o

  constructor() {
    super();
    this.setupCleanupInterval();
  }

  // üîç DEBUGGING: Gerar ID √∫nico para rastreamento
  private generateProcessingId(): string {
    return `proc_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
  }

  // üîç DEBUGGING: Registrar evento no tracker
  private logDebugEvent(sessionId: string, channel: string, event: string, details: any = {}) {
    const key = `${sessionId}:${channel}`;
    if (!this.debugTracker.has(key)) {
      this.debugTracker.set(key, []);
    }
    
    const logEntry = {
      timestamp: Date.now(),
      time: new Date().toISOString(),
      event,
      ...details
    };
    
    this.debugTracker.get(key)!.push(logEntry);
    
    // Log detalhado no console
    console.log(`üîç DEBUG [${key}] ${event}:`, JSON.stringify(details, null, 2));
    
    // Manter apenas √∫ltimos 50 eventos por canal
    const events = this.debugTracker.get(key)!;
    if (events.length > 50) {
      events.splice(0, events.length - 50);
    }
  }

  // Processar chunk de √°udio recebido
  public processAudioChunk(audioChunk: AudioChunk): void {
    try {
      const { sessionId, channel, audioData, timestamp, sampleRate } = audioChunk;
      const bufferKey = `${sessionId}:${channel}`;
      const currentTime = Date.now();

      // Aplicar Voice Activity Detection
      const hasVoiceActivity = this.detectVoiceActivity(audioData);
      
      // Calcular RMS para logs de debug
      const rms = this.calculateRMS(audioData);
      
      if (hasVoiceActivity) {
        // Incrementar contador de chunks consecutivos
        const currentCount = this.consecutiveVoiceChunks.get(bufferKey) || 0;
        this.consecutiveVoiceChunks.set(bufferKey, currentCount + 1);
        
        // S√≥ processar se tiver chunks consecutivos suficientes
        if (currentCount + 1 >= this.minConsecutiveChunks) {
          // Atualizar timestamp da √∫ltima atividade de voz
          this.lastVoiceActivity.set(bufferKey, currentTime);
          
          // Inicializar buffer de frase se n√£o existir
          const phraseKey = `phrase_${bufferKey}`;
          if (!this.phraseTimestamps.has(phraseKey)) {
            this.phraseTimestamps.set(phraseKey, currentTime);
            console.log(`üé¨ Iniciando nova frase: ${channel}`);
          }
          
          // Log de debug ocasional para n√£o spam
          if (Math.random() < 0.02 && process.env.NODE_ENV === 'development') {
            console.log(`üéôÔ∏è Voz cont√≠nua detectada: ${channel} - RMS: ${rms.toFixed(4)} (chunks: ${currentCount + 1})`);
          }
          
          this.emit('audio:voice_activity', {
            sessionId,
            channel,
            isActive: true
          });

          // Adicionar ao buffer principal
          if (!this.buffers.has(bufferKey)) {
            this.buffers.set(bufferKey, []);
          }
          const buffer = this.buffers.get(bufferKey)!;
          buffer.push(new Float32Array(audioData));

          // Adicionar ao buffer de frase
          if (!this.phraseBuffers.has(phraseKey)) {
            this.phraseBuffers.set(phraseKey, []);
          }
          const phraseBuffer = this.phraseBuffers.get(phraseKey)!;
          phraseBuffer.push(new Float32Array(audioData));

          // Calcular tamanho total do buffer
          const totalSamples = buffer.reduce((sum, chunk) => sum + chunk.length, 0);

          // DESABILITADO: N√£o processar por buffer cheio, apenas por fim de frase
          if (!this.disablePartialProcessing && totalSamples >= this.maxBufferSize) {
            this.flushBuffer(bufferKey, sessionId, channel, sampleRate);
          }
        } else {
          // Ainda n√£o tem chunks suficientes, apenas log de debug ocasional
          if (Math.random() < 0.1 && process.env.NODE_ENV === 'development') {
            console.log(`üîç Verificando consist√™ncia: ${channel} - RMS: ${rms.toFixed(4)} (chunks: ${currentCount + 1}/${this.minConsecutiveChunks})`);
          }
        }
      } else {
        // Reset do contador de chunks consecutivos
        this.consecutiveVoiceChunks.set(bufferKey, 0);
        // Verificar se h√° buffer para processar ap√≥s sil√™ncio
        const lastActivity = this.lastVoiceActivity.get(bufferKey) || 0;
        const silenceDuration = currentTime - lastActivity;
        
        // Log de sil√™ncio apenas ocasionalmente para n√£o spam
        if (Math.random() < 0.01 && process.env.NODE_ENV === 'development') {
          console.log(`üîá Sil√™ncio: ${channel} - RMS: ${rms.toFixed(4)} (sil√™ncio h√° ${silenceDuration}ms)`);
        }
        
        // PRINCIPAL: Verificar se deve finalizar frase por sil√™ncio prolongado
        const phraseKey = `phrase_${bufferKey}`;
        if (silenceDuration > this.phraseEndSilenceMs && this.phraseBuffers.has(phraseKey)) {
          const phraseBuffer = this.phraseBuffers.get(phraseKey)!;
          if (phraseBuffer.length > 0) {
            console.log(`üîö Finalizando frase ap√≥s ${silenceDuration}ms de sil√™ncio: ${channel}`);
            this.flushPhraseBuffer(phraseKey, sessionId, channel, sampleRate);
          }
        }
        
        // DESABILITADO: N√£o processar buffers √≥rf√£os no modo de frases completas
        // Apenas limpar para n√£o acumular mem√≥ria
        if (silenceDuration > this.silenceThresholdMs && this.buffers.has(bufferKey)) {
          const buffer = this.buffers.get(bufferKey)!;
          if (buffer.length > 0 && !this.phraseBuffers.has(phraseKey)) {
            // Apenas limpar sem processar quando em modo de frases completas
            this.buffers.set(bufferKey, []);
            console.log(`üßπ Buffer √≥rf√£o limpo sem processar: ${channel} (modo frases completas)`);
          }
        }
        
        this.emit('audio:silence', { sessionId, channel });
      }
    } catch (error) {
      console.error('Erro ao processar chunk de √°udio:', error);
      this.emit('error', error as Error);
    }
  }

  // Detectar atividade de voz (VAD simples)
  private detectVoiceActivity(audioData: Float32Array): boolean {
    // Calcular RMS (Root Mean Square) do √°udio
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i];
    }
    const rms = Math.sqrt(sum / audioData.length);

    return rms > this.vadThreshold;
  }

  // Calcular volume m√©dio do √°udio
  private calculateAverageVolume(audioData: Float32Array): number {
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
      sum += Math.abs(audioData[i]);
    }
    return sum / audioData.length;
  }

  // Calcular RMS (Root Mean Square) do √°udio
  private calculateRMS(audioData: Float32Array): number {
    let sum = 0;
    for (let i = 0; i < audioData.length; i++) {
      sum += audioData[i] * audioData[i];
    }
    return Math.sqrt(sum / audioData.length);
  }

  // üéöÔ∏è NORMALIZAR √ÅUDIO para melhorar qualidade da transcri√ß√£o
  private normalizeAudio(audioData: Float32Array): Float32Array {
    if (audioData.length === 0) return audioData;

    // Encontrar valor m√°ximo absoluto
    let maxValue = 0;
    for (let i = 0; i < audioData.length; i++) {
      const absValue = Math.abs(audioData[i]);
      if (absValue > maxValue) {
        maxValue = absValue;
      }
    }

    // Se √°udio muito baixo, n√£o normalizar (pode ser sil√™ncio)
    if (maxValue < 0.001) {
      return audioData;
    }

    // Normalizar para 85% do m√°ximo (evita clipping e mant√©m din√¢mica)
    const targetLevel = 0.85;
    const normalizationFactor = targetLevel / maxValue;
    
    const normalizedAudio = new Float32Array(audioData.length);
    for (let i = 0; i < audioData.length; i++) {
      normalizedAudio[i] = audioData[i] * normalizationFactor;
    }

    const originalRMS = this.calculateRMS(audioData);
    const normalizedRMS = this.calculateRMS(normalizedAudio);
    
    console.log(`üéöÔ∏è √Åudio normalizado: ${originalRMS.toFixed(4)} ‚Üí ${normalizedRMS.toFixed(4)} (fator: ${normalizationFactor.toFixed(2)})`);
    
    return normalizedAudio;
  }

  // Processar buffer acumulado
  // üõ°Ô∏è PROTE√á√ÉO GLOBAL CONTRA DUPLICA√á√ïES
  private canProcessChannel(sessionId: string, channel: 'doctor' | 'patient'): boolean {
    const globalKey = `${sessionId}:${channel}`;
    
    // Verificar lock global
    if (this.globalProcessingLock.get(globalKey)) {
      console.log(`üõ°Ô∏è LOCK GLOBAL ATIVO - Bloqueando processamento: ${channel}`);
      return false;
    }
    
    // Verificar processamento recente (prote√ß√£o temporal)
    const lastProcessed = this.lastProcessedTimestamp.get(globalKey) || 0;
    const timeSinceLastProcessing = Date.now() - lastProcessed;
    if (timeSinceLastProcessing < 8000) { // 8 segundos m√≠nimo - AUMENTADO
      console.log(`üõ°Ô∏è PROTE√á√ÉO TEMPORAL - Bloqueando processamento: ${channel} (${timeSinceLastProcessing}ms atr√°s)`);
      return false;
    }
    
    return true;
  }

  // Processar e emitir buffer de frase completa
  private flushPhraseBuffer(
    phraseKey: string,
    sessionId: string,
    channel: 'doctor' | 'patient',
    sampleRate: number
  ): void {
    const processingId = this.generateProcessingId();
    
    // üîç DEBUG: Log de entrada
    this.logDebugEvent(sessionId, channel, 'FLUSH_PHRASE_BUFFER_START', {
      processingId,
      phraseKey,
      sampleRate,
      hasBuffer: this.phraseBuffers.has(phraseKey),
      bufferLength: this.phraseBuffers.get(phraseKey)?.length || 0
    });

    try {
      const phraseBuffer = this.phraseBuffers.get(phraseKey);
      if (!phraseBuffer || phraseBuffer.length === 0) {
        this.logDebugEvent(sessionId, channel, 'FLUSH_PHRASE_BUFFER_EMPTY', { processingId });
        return;
      }

      // üõ°Ô∏è PROTE√á√ÉO GLOBAL PRIMEIRA - Verificar se pode processar este canal
      if (!this.canProcessChannel(sessionId, channel)) {
        this.logDebugEvent(sessionId, channel, 'FLUSH_PHRASE_BUFFER_BLOCKED', { 
          processingId,
          reason: 'canProcessChannel_failed'
        });
        return;
      }

      // PROTE√á√ÉO: Verificar se j√° est√° processando esta frase
      if (this.processingInProgress.get(phraseKey)) {
        this.logDebugEvent(sessionId, channel, 'FLUSH_PHRASE_BUFFER_ALREADY_PROCESSING', { 
          processingId,
          phraseKey
        });
        console.log(`‚ö†Ô∏è Processamento j√° em andamento para: ${phraseKey} - IGNORANDO`);
        return;
      }

      // üîí MARCAR LOCKS GLOBAIS
      const globalChannelKey = `${sessionId}:${channel}`;
      this.processingInProgress.set(phraseKey, true);
      this.globalProcessingLock.set(globalChannelKey, true);

      this.logDebugEvent(sessionId, channel, 'FLUSH_PHRASE_BUFFER_LOCKS_SET', {
        processingId,
        phraseKey,
        globalChannelKey
      });

      console.log(`üîí LOCKS ATIVADOS: ${phraseKey} + global ${globalChannelKey}`);

      // Calcular tamanho total
      const totalSamples = phraseBuffer.reduce((sum, chunk) => sum + chunk.length, 0);
      const duration = (totalSamples / sampleRate) * 1000; // em ms

      // Verificar dura√ß√£o m√≠nima (mais flex√≠vel)
      if (duration < this.minVoiceDurationMs) {
        console.log(`‚è≠Ô∏è Frase muito curta ignorada: ${channel} - ${duration.toFixed(0)}ms`);
        this.phraseBuffers.delete(phraseKey);
        this.phraseTimestamps.delete(phraseKey);
        return;
      }

      // Verificar se frase n√£o √© muito longa (evitar perda de contexto)
      if (duration > this.maxPhraseLength) {
        console.log(`üìè Frase muito longa, processando: ${channel} - ${duration.toFixed(0)}ms`);
      }

      // Concatenar todos os chunks da frase
      const concatenatedAudio = new Float32Array(totalSamples);
      let offset = 0;
      for (const chunk of phraseBuffer) {
        concatenatedAudio.set(chunk, offset);
        offset += chunk.length;
      }

      // üéöÔ∏è NORMALIZAR √ÅUDIO para melhor qualidade de transcri√ß√£o
      const normalizedAudio = this.normalizeAudio(concatenatedAudio);

      // Converter para WAV com √°udio normalizado
      const audioBuffer = this.float32ToWavBuffer(normalizedAudio, sampleRate);

      // Detectar atividade de voz final
      const hasVoiceActivity = this.detectVoiceActivity(concatenatedAudio);
      const averageVolume = this.calculateAverageVolume(concatenatedAudio);

      // Criar chunk processado da frase completa
      const processedChunk: ProcessedAudioChunk = {
        sessionId,
        channel,
        audioBuffer,
        timestamp: Date.now(),
        sampleRate,
        duration,
        hasVoiceActivity,
        averageVolume
      };

      // üîç DEBUG: Log antes de emitir evento
      this.logDebugEvent(sessionId, channel, 'AUDIO_PROCESSED_EVENT_EMIT', {
        processingId,
        duration: Math.round(duration),
        audioBufferSize: audioBuffer.length,
        hasVoiceActivity,
        averageVolume,
        chunkId: processedChunk.sessionId + ':' + processedChunk.channel + ':' + processedChunk.timestamp
      });

      // Emitir evento de frase processada
      this.emit('audio:processed', processedChunk);

      console.log(`üéØ FRASE COMPLETA PROCESSADA: ${channel} - ${duration.toFixed(0)}ms - ${audioBuffer.length} bytes - ENVIANDO PARA WHISPER`);

      // Registrar timestamp do processamento
      const finalGlobalKey = `${sessionId}:${channel}`;
      this.lastProcessedTimestamp.set(finalGlobalKey, Date.now());

      // Limpar buffers de frase
      this.phraseBuffers.delete(phraseKey);
      this.phraseTimestamps.delete(phraseKey);

    } catch (error) {
      console.error('Erro ao processar buffer de frase:', error);
      this.emit('error', error as Error);
    } finally {
      // üîì SEMPRE LIBERAR TODOS OS LOCKS
      const unlockGlobalKey = `${sessionId}:${channel}`;
      this.processingInProgress.set(phraseKey, false);
      
      // Liberar lock global ap√≥s delay para evitar processamento imediato
      setTimeout(() => {
        this.globalProcessingLock.set(unlockGlobalKey, false);
        console.log(`üîì LOCK GLOBAL LIBERADO: ${unlockGlobalKey}`);
      }, 2000); // 2 segundos de delay
    }
  }

  private flushBuffer(
    bufferKey: string,
    sessionId: string,
    channel: 'doctor' | 'patient',
    sampleRate: number
  ): void {
    const processingId = this.generateProcessingId();
    
    // üîç DEBUG: Log de entrada no flushBuffer
    this.logDebugEvent(sessionId, channel, 'FLUSH_BUFFER_START', {
      processingId,
      bufferKey,
      sampleRate,
      hasBuffer: this.buffers.has(bufferKey),
      bufferLength: this.buffers.get(bufferKey)?.length || 0
    });

    // üõ°Ô∏è PROTE√á√ÉO GLOBAL - Verificar se pode processar este canal
    if (!this.canProcessChannel(sessionId, channel)) {
      this.logDebugEvent(sessionId, channel, 'FLUSH_BUFFER_BLOCKED', {
        processingId,
        reason: 'canProcessChannel_failed'
      });
      console.log(`üõ°Ô∏è flushBuffer BLOQUEADO por prote√ß√£o global: ${channel}`);
      return;
    }

    const buffer = this.buffers.get(bufferKey);
    if (!buffer || buffer.length === 0) {
      this.logDebugEvent(sessionId, channel, 'FLUSH_BUFFER_EMPTY', { processingId });
      return;
    }

    try {
      // Concatenar todos os chunks do buffer
      const totalSamples = buffer.reduce((sum, chunk) => sum + chunk.length, 0);
      const concatenatedAudio = new Float32Array(totalSamples);
      
      let offset = 0;
      for (const chunk of buffer) {
        concatenatedAudio.set(chunk, offset);
        offset += chunk.length;
      }

      // Converter Float32Array para Buffer WAV para melhor compatibilidade com Whisper
      const audioBuffer = this.float32ToWavBuffer(concatenatedAudio, sampleRate);

      // Calcular dura√ß√£o
      const duration = (totalSamples / sampleRate) * 1000; // em ms

      // Detectar atividade de voz no buffer concatenado
      const hasVoiceActivity = this.detectVoiceActivity(concatenatedAudio);

      // Calcular volume m√©dio
      const averageVolume = this.calculateAverageVolume(concatenatedAudio);

      // Criar chunk processado
      const processedChunk: ProcessedAudioChunk = {
        sessionId,
        channel,
        audioBuffer,
        timestamp: Date.now(),
        sampleRate,
        duration,
        hasVoiceActivity,
        averageVolume
      };

      // Emitir evento de √°udio processado
      this.emit('audio:processed', processedChunk);

      // Limpar buffer
      this.buffers.set(bufferKey, []);

      console.log(`‚úÖ Buffer processado: ${channel} - ${duration.toFixed(0)}ms - ${audioBuffer.length} bytes`);
    } catch (error) {
      console.error('Erro ao processar buffer:', error);
      this.emit('error', error as Error);
    }
  }

  // Converter Float32Array para Buffer WAV completo
  private float32ToWavBuffer(float32Array: Float32Array, sampleRate: number): Buffer {
    const length = float32Array.length;
    const buffer = Buffer.allocUnsafe(44 + length * 2);
    
    // WAV Header
    buffer.write('RIFF', 0);                                    // ChunkID
    buffer.writeUInt32LE(36 + length * 2, 4);                  // ChunkSize
    buffer.write('WAVE', 8);                                    // Format
    buffer.write('fmt ', 12);                                   // Subchunk1ID
    buffer.writeUInt32LE(16, 16);                              // Subchunk1Size
    buffer.writeUInt16LE(1, 20);                               // AudioFormat (PCM)
    buffer.writeUInt16LE(1, 22);                               // NumChannels (mono)
    buffer.writeUInt32LE(sampleRate, 24);                      // SampleRate
    buffer.writeUInt32LE(sampleRate * 2, 28);                  // ByteRate
    buffer.writeUInt16LE(2, 32);                               // BlockAlign
    buffer.writeUInt16LE(16, 34);                              // BitsPerSample
    buffer.write('data', 36);                                   // Subchunk2ID
    buffer.writeUInt32LE(length * 2, 40);                      // Subchunk2Size
    
    // Audio Data (16-bit PCM)
    for (let i = 0; i < length; i++) {
      const sample = Math.max(-1, Math.min(1, float32Array[i]));
      const int16Sample = Math.round(sample * 32767);
      buffer.writeInt16LE(int16Sample, 44 + i * 2);
    }
    
    return buffer;
  }

  // Converter Float32Array para Buffer Int16 (mantido para compatibilidade)
  private float32ToInt16Buffer(float32Array: Float32Array): Buffer {
    const buffer = Buffer.allocUnsafe(float32Array.length * 2);
    
    for (let i = 0; i < float32Array.length; i++) {
      // Converter de float (-1 a 1) para int16 (-32768 a 32767)
      const sample = Math.max(-1, Math.min(1, float32Array[i]));
      const int16Sample = Math.round(sample * 32767);
      buffer.writeInt16LE(int16Sample, i * 2);
    }
    
    return buffer;
  }

  // For√ßar processamento de frases pendentes (PRIORIT√ÅRIO)
  public flushPendingPhrases(sessionId: string): void {
    const doctorKey = `${sessionId}:doctor`;
    const patientKey = `${sessionId}:patient`;
    const doctorPhraseKey = `phrase_${doctorKey}`;
    const patientPhraseKey = `phrase_${patientKey}`;

    // Processar frases pendentes primeiro
    if (this.phraseBuffers.has(doctorPhraseKey)) {
      console.log(`üîÑ For√ßando finaliza√ß√£o de frase: doctor`);
      this.flushPhraseBuffer(doctorPhraseKey, sessionId, 'doctor', 44100);
    }

    if (this.phraseBuffers.has(patientPhraseKey)) {
      console.log(`üîÑ For√ßando finaliza√ß√£o de frase: patient`);
      this.flushPhraseBuffer(patientPhraseKey, sessionId, 'patient', 44100);
    }
  }

  // For√ßar processamento de buffer pendente (BACKUP)
  public flushPendingBuffers(sessionId: string): void {
    const doctorKey = `${sessionId}:doctor`;
    const patientKey = `${sessionId}:patient`;

    if (this.buffers.has(doctorKey)) {
      this.flushBuffer(doctorKey, sessionId, 'doctor', 44100);
    }

    if (this.buffers.has(patientKey)) {
      this.flushBuffer(patientKey, sessionId, 'patient', 44100);
    }
  }

  // Limpar buffers de uma sess√£o
  public clearSession(sessionId: string): void {
    const keysToRemove = Array.from(this.buffers.keys()).filter(key => 
      key.startsWith(`${sessionId}:`)
    );

    for (const key of keysToRemove) {
      this.buffers.delete(key);
      this.lastVoiceActivity.delete(key);
      this.consecutiveVoiceChunks.delete(key);
      
      // Limpar buffers de frase correspondentes
      const phraseKey = `phrase_${key}`;
      this.phraseBuffers.delete(phraseKey);
      this.phraseTimestamps.delete(phraseKey);
      this.processingInProgress.delete(phraseKey);
      this.lastProcessedTimestamp.delete(key); // Usar key diretamente para globalKey
      this.globalProcessingLock.delete(key); // üõ°Ô∏è Limpar lock global
    }

    console.log(`üßπ Buffers limpos para sess√£o: ${sessionId}`);
  }

  // Limpar todas as sess√µes
  public clearAllSessions(): void {
    this.buffers.clear();
    this.lastVoiceActivity.clear();
    this.consecutiveVoiceChunks.clear();
    this.phraseBuffers.clear();
    this.phraseTimestamps.clear();
    this.processingInProgress.clear();
    this.lastProcessedTimestamp.clear();
    this.processedChunkIds.clear(); // üõ°Ô∏è Limpar IDs processados
    this.globalProcessingLock.clear(); // üõ°Ô∏è Limpar locks globais
    this.debugTracker.clear(); // üîç Limpar debug tracker
    console.log('üßπ Todos os buffers e locks foram limpos');
  }

  // üîç DEBUGGING: Obter relat√≥rio de eventos
  public getDebugReport(sessionId?: string): any {
    if (sessionId) {
      const doctorKey = `${sessionId}:doctor`;
      const patientKey = `${sessionId}:patient`;
      return {
        doctor: this.debugTracker.get(doctorKey) || [],
        patient: this.debugTracker.get(patientKey) || []
      };
    }
    
    // Retornar todos os eventos
    const report: any = {};
    for (const [key, events] of this.debugTracker.entries()) {
      report[key] = events;
    }
    return report;
  }

  // üîç DEBUGGING: Contar eventos por tipo
  public getDebugSummary(sessionId: string): any {
    const doctorKey = `${sessionId}:doctor`;
    const patientKey = `${sessionId}:patient`;
    
    const summarize = (events: any[]) => {
      const summary: any = {};
      events.forEach(event => {
        summary[event.event] = (summary[event.event] || 0) + 1;
      });
      return summary;
    };
    
    return {
      doctor: summarize(this.debugTracker.get(doctorKey) || []),
      patient: summarize(this.debugTracker.get(patientKey) || [])
    };
  }

  // Configurar limpeza autom√°tica de buffers antigos
  private setupCleanupInterval(): void {
    setInterval(() => {
      // TODO: Implementar limpeza de buffers antigos
      // Por enquanto, apenas log
      const bufferCount = this.buffers.size;
      if (bufferCount > 0) {
        console.log(`üìä Buffers ativos: ${bufferCount}`);
      }
    }, 30000); // A cada 30 segundos
  }

  // Configurar dura√ß√£o do buffer
  public setBufferDuration(durationMs: number): void {
    this.bufferDuration = Math.max(100, Math.min(5000, durationMs));
    this.maxBufferSize = Math.floor((this.bufferDuration / 1000) * 44100);
    console.log(`‚è±Ô∏è Buffer duration configurado: ${this.bufferDuration}ms`);
  }

  // Obter estat√≠sticas
  public getStats(): object {
    return {
      activeBuffers: this.buffers.size,
      configuracao: {
        vadThreshold: this.vadThreshold,
        minVoiceDurationMs: this.minVoiceDurationMs,
        silenceThresholdMs: this.silenceThresholdMs,
        maxBufferSize: this.maxBufferSize,
        bufferDuration: this.bufferDuration
      },
      bufferDetails: Array.from(this.buffers.entries()).map(([key, buffer]) => ({
        key,
        chunks: buffer.length,
        totalSamples: buffer.reduce((sum, chunk) => sum + chunk.length, 0)
      }))
    };
  }

  // Configurar threshold de VAD dinamicamente
  public setVADThreshold(threshold: number): void {
    this.vadThreshold = Math.max(0.001, Math.min(1.0, threshold));
    console.log(`üéõÔ∏è VAD Threshold atualizado: ${this.vadThreshold}`);
  }

  // Configurar dura√ß√£o m√≠nima de voz
  public setMinVoiceDuration(durationMs: number): void {
    this.minVoiceDurationMs = Math.max(100, durationMs);
    console.log(`‚è±Ô∏è Dura√ß√£o m√≠nima de voz atualizada: ${this.minVoiceDurationMs}ms`);
  }

  // Configurar threshold de sil√™ncio
  public setSilenceThreshold(thresholdMs: number): void {
    this.silenceThresholdMs = Math.max(500, thresholdMs);
    console.log(`üîá Threshold de sil√™ncio atualizado: ${this.silenceThresholdMs}ms`);
  }

  // Obter configura√ß√£o atual
  public getConfiguration(): object {
    return {
      vadThreshold: this.vadThreshold,
      minVoiceDurationMs: this.minVoiceDurationMs,
      silenceThresholdMs: this.silenceThresholdMs,
      maxBufferSize: this.maxBufferSize,
      bufferDuration: this.bufferDuration
    };
  }
}

// Inst√¢ncia singleton do processador de √°udio
export const audioProcessor = new AudioProcessor();
